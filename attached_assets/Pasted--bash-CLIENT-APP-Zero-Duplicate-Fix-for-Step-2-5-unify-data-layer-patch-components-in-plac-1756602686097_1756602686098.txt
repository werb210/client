```bash
# CLIENT APP — Zero-Duplicate Fix for Step 2 & 5 (unify data layer, patch components in-place, verify, then remove legacy)
# Safe & idempotent. Modifies existing files when possible. If replacement is required:
#   1) writes new code,
#   2) builds & tests it,
#   3) ONLY THEN removes legacy files (or quarantines if NUKE!=1).
# Produces reports under reports/client-zero-dupe-<ts>/ and quarantines under .trash-client-<ts>/ (unless NUKE=1).

set -euo pipefail

TS="$(date +%F_%H-%M-%S)"
R="reports/client-zero-dupe-$TS"
TRASH=".trash-client-$TS"
mkdir -p "$R" "$TRASH"
command -v rg >/dev/null || alias rg='grep -R'

echo "== CLIENT ZERO-DUPE RUN @$TS ==" | tee "$R/00_context.txt"

# --------------------------------------------------------------------
# 0) Canonical file decisions (prefer existing to avoid duplicates)
# --------------------------------------------------------------------
CAN_FETCHER=""
for f in client/src/api/products.ts client/src/lib/api.ts client/src/api/index.ts; do
  [ -f "$f" ] && CAN_FETCHER="$f" && break
done
[ -z "$CAN_FETCHER" ] && CAN_FETCHER="client/src/api/products.ts"

# normalize helper preference
CAN_NORMALIZE=""
for f in client/src/api/normalize.ts client/src/lib/normalize.ts; do
  [ -f "$f" ] && CAN_NORMALIZE="$f" && break
done
[ -z "$CAN_NORMALIZE" ] && CAN_NORMALIZE="client/src/api/normalize.ts"

echo "Fetcher:   $CAN_FETCHER"   | tee -a "$R/00_context.txt"
echo "Normalize: $CAN_NORMALIZE" | tee -a "$R/00_context.txt"

# --------------------------------------------------------------------
# 1) Ensure ONE normalize module (modify existing or create)
# --------------------------------------------------------------------
if [ -f "$CAN_NORMALIZE" ]; then
  # Patch in-place to guarantee CanonicalProduct + toCanonical signature
  node - <<'NODE' "$CAN_NORMALIZE"
const fs=require('fs'); const p=process.argv[2]; let s=fs.readFileSync(p,'utf8'); const o=s;
if(!s.includes('export type CanonicalProduct')){
  s = `export type CanonicalProduct = {
  id?: string|number;
  name: string;
  category: string;
  lenderName: string;
  country: string;
  minAmount: number;
  maxAmount: number;
  raw: any;
};
` + s;
}
if(!/export\s+const\s+toCanonical\s*=/.test(s)){
  s += `
const num = (v:any, d=0)=>{ const n=Number((v??'').toString().replace(/[$,_\\s]/g,'')); return Number.isFinite(n)? n : d; };
const up  = (s:any)=> (s??"").toString().trim().toUpperCase();
export const toCanonical = (p:any) => {
  const name = p.name ?? p.productName ?? p.title ?? "";
  const lenderName = p.lenderName ?? p.lender_name ?? p.lender ?? "";
  const cc = up(p.country ?? p.countryCode ?? p.region ?? "");
  const country = cc==="CANADA" ? "CA" : cc==="USA" ? "US" : (cc==="UNITED STATES"?"US": (cc==="US"||cc==="CA"?cc:"NA"));
  const min = num(p.minAmount ?? p.min_amount ?? p.min ?? 0, 0);
  const maxRaw = p.maxAmount ?? p.max_amount ?? p.max ?? null;
  const max = maxRaw==null ? Number.POSITIVE_INFINITY : num(maxRaw, Number.POSITIVE_INFINITY);
  const category = p.category ?? p.type ?? "Unknown";
  return { id:p.id, name, category, lenderName, country, minAmount:min, maxAmount:max, raw:p };
};
`;
}
if(s!==o){ fs.writeFileSync(p,s); console.log("Patched normalize:",p); }
NODE
else
  mkdir -p "$(dirname "$CAN_NORMALIZE")"
  cat > "$CAN_NORMALIZE" <<'TS'
export type CanonicalProduct = {
  id?: string|number;
  name: string;
  category: string;
  lenderName: string;
  country: string;
  minAmount: number;
  maxAmount: number;
  raw: any;
};
const num = (v:any, d=0)=>{ const n=Number((v??'').toString().replace(/[$,_\s]/g,'')); return Number.isFinite(n)? n : d; };
const up  = (s:any)=> (s??"").toString().trim().toUpperCase();
export const toCanonical = (p:any) => {
  const name = p.name ?? p.productName ?? p.title ?? "";
  const lenderName = p.lenderName ?? p.lender_name ?? p.lender ?? "";
  const cc = up(p.country ?? p.countryCode ?? p.region ?? "");
  const country = cc==="CANADA" ? "CA" : cc==="USA" ? "US" : (cc==="UNITED STATES"?"US": (cc==="US"||cc==="CA"?cc:"NA"));
  const min = num(p.minAmount ?? p.min_amount ?? p.min ?? 0, 0);
  const maxRaw = p.maxAmount ?? p.max_amount ?? p.max ?? null;
  const max = maxRaw==null ? Number.POSITIVE_INFINITY : num(maxRaw, Number.POSITIVE_INFINITY);
  const category = p.category ?? p.type ?? "Unknown";
  return { id:p.id, name, category, lenderName, country, minAmount:min, maxAmount:max, raw:p };
};
TS
  echo "Created normalize: $CAN_NORMALIZE" | tee -a "$R/20_actions.txt"
fi

# --------------------------------------------------------------------
# 2) Unify fetcher (patch existing $CAN_FETCHER in-place; no new file unless needed)
#    Exports: fetchProducts(), fetchRequiredDocs(), getRecommendedProducts()
# --------------------------------------------------------------------
mkdir -p "$(dirname "$CAN_FETCHER")"
if [ ! -f "$CAN_FETCHER" ]; then
  cat > "$CAN_FETCHER" <<'TS'
import { toCanonical } from "./normalize";
type Any = any;
const BASES = [
  (import.meta.env.VITE_STAFF_API_URL || "https://staff.boreal.financial/api").replace(/\/+$/,''),
  "http://localhost:5000/api"
];
const TOKEN = import.meta.env.VITE_CLIENT_APP_SHARED_TOKEN || "";
const headers: Record<string,string> = TOKEN ? { Authorization: `Bearer ${TOKEN}` } : {};
const norm = (d:Any)=> Array.isArray(d) ? d : (d.items || d.required_products || d.required_documents || []);
export async function fetchProducts(): Promise<Any[]> {
  for (const b of BASES) {
    try { const r = await fetch(`${b}/v1/products`, { headers, credentials:"include" }); if (r.ok) return norm(await r.json()); if (r.status!==404) console.warn("products fetch",b,r.status); } catch {}
  } return [];
}
export async function fetchRequiredDocs(): Promise<Any[]> {
  for (const b of BASES) {
    try { const r = await fetch(`${b}/required-docs`, { credentials:"include" }); if (r.ok){ const j=await r.json(); return Array.isArray(j)?j:(j.required_documents||j.items||[]);} } catch {}
  } return [];
}
function getStep1(){ try { return JSON.parse(localStorage.getItem("formData")||"null")||{}; } catch { return {}; } }
export async function getRecommendedProducts(){
  const raw = await fetchProducts();
  const list = raw.map(toCanonical);
  const s1:any = getStep1();
  const amount = Number(s1.amountRequested ?? s1.loanAmount ?? s1.requestedAmount ?? s1.requested_amount ?? s1.amount ?? s1.fundsNeeded ?? s1.fundingAmount ?? s1.loan_size ?? 0) || 0;
  const cc = (s1.country ?? s1.countryCode ?? s1.applicantCountry ?? s1.region ?? "").toString().toUpperCase();
  const country = cc==="CANADA"?"CA":(cc==="USA"||cc==="UNITED STATES"?"US":cc);
  const matches = list.filter(p => (!country || p.country===country) && (!amount || (p.minAmount<=amount && amount<=p.maxAmount)));
  return { all:list, matches };
}
export default { fetchProducts, fetchRequiredDocs, getRecommendedProducts };
TS
  echo "Created fetcher: $CAN_FETCHER" | tee -a "$R/20_actions.txt"
else
  node - <<'NODE' "$CAN_FETCHER"
const fs=require('fs'); const p=process.argv[2]; let s=fs.readFileSync(p,'utf8'); const o=s;
if(!/fetchProducts\s*\(/.test(s)){ s += `
import { toCanonical } from "./normalize";
type Any = any;
const BASES = [
  (import.meta.env.VITE_STAFF_API_URL || "https://staff.boreal.financial/api").replace(/\\/+\$/,''),
  "http://localhost:5000/api"
];
const TOKEN = import.meta.env.VITE_CLIENT_APP_SHARED_TOKEN || "";
const headers: Record<string,string> = TOKEN ? { Authorization: \`Bearer \${TOKEN}\` } : {};
const norm = (d:Any)=> Array.isArray(d) ? d : (d.items || d.required_products || d.required_documents || []);
export async function fetchProducts(): Promise<Any[]> {
  for (const b of BASES) {
    try { const r = await fetch(\`\${b}/v1/products\`, { headers, credentials:"include" }); if (r.ok) return norm(await r.json()); if (r.status!==404) console.warn("products fetch",b,r.status); } catch {}
  } return [];
}`; }
if(!/fetchRequiredDocs\s*\(/.test(s)){ s += `
export async function fetchRequiredDocs(): Promise<Any[]> {
  for (const b of BASES) {
    try { const r = await fetch(\`\${b}/required-docs\`, { credentials:"include" }); if (r.ok){ const j=await r.json(); return Array.isArray(j)?j:(j.required_documents||j.items||[]);} } catch {}
  } return [];
}`; }
if(!/getRecommendedProducts\s*\(/.test(s)){ s += `
function getStep1(){ try { return JSON.parse(localStorage.getItem("formData")||"null")||{}; } catch { return {}; } }
export async function getRecommendedProducts(){
  const raw = await fetchProducts();
  const { toCanonical } = await import("./normalize");
  const list = raw.map(toCanonical);
  const s1:any = getStep1();
  const amount = Number(s1.amountRequested ?? s1.loanAmount ?? s1.requestedAmount ?? s1.requested_amount ?? s1.amount ?? s1.fundsNeeded ?? s1.fundingAmount ?? s1.loan_size ?? 0) || 0;
  const cc = (s1.country ?? s1.countryCode ?? s1.applicantCountry ?? s1.region ?? "").toString().toUpperCase();
  const country = cc==="CANADA"?"CA":(cc==="USA"||cc==="UNITED STATES"?"US":cc);
  const matches = list.filter(p => (!country || p.country===country) && (!amount || (p.minAmount<=amount && amount<=p.maxAmount)));
  return { all:list, matches };
}`; }
if(s!==o){ fs.writeFileSync(p,s); console.log("Patched fetcher:",p); }
NODE
fi

# --------------------------------------------------------------------
# 3) Patch Step 2 components IN-PLACE to use getRecommendedProducts()
# --------------------------------------------------------------------
rg -l -n --hidden -S 'Step2|Recommendation' client/src 2>/dev/null | tee "$R/step2_files.txt" >/dev/null || true
while IFS= read -r f; do
  [ -f "$f" ] || continue
  node - <<'NODE' "$f" "$CAN_FETCHER"
const fs=require('fs'); const [p,fetcher]=process.argv.slice(2); let s=fs.readFileSync(p,'utf8'); const o=s; let changed=false;
const rel = (()=>{ // compute relative import to fetcher
  const path=require('path'); let rel=path.relative(path.dirname(p), fetcher).replace(/\\/g,'/');
  if(!/^\.\.?\//.test(rel)) rel='./'+rel; return rel.replace(/\.ts$/, '');
})();
if(!/getRecommendedProducts/.test(s)){
  if(/from\s+["'][^"']*\/api\/products[^"']*["']/.test(s)){
    s=s.replace(/from\s+["'][^"']*\/api\/products[^"']*["']/,'from "'+rel+'"');
    s=s.replace(/\bfetchProducts\s*\(\s*\)/g,'(await getRecommendedProducts()).matches');
    if(!/getRecommendedProducts/.test(s)) s=s.replace(/import\s*{([^}]+)}/, (m,g)=> m.replace(g, g+', getRecommendedProducts'));
    changed=true;
  } else if(!/from\s+["'][^"']+["']/.test(s) || /\/\/\s*<imports>/.test(s)){
    s = s.replace(/^\s*import[\s\S]*?;\s*/m, m=> m + `\nimport { getRecommendedProducts } from "${rel}";\n`);
    s = s.replace(/return\s*\(/, 'const __reco = await getRecommendedProducts();\nconst products = __reco.matches;\nreturn (');
    changed=true;
  }
}
if(changed && s!==o){ fs.writeFileSync(p,s); console.log("Rewired Step2 ->",p); }
NODE
done < "$R/step2_files.txt"

# --------------------------------------------------------------------
# 4) Patch Step 5 components IN-PLACE to use fetchRequiredDocs() and guard legacy fields
# --------------------------------------------------------------------
rg -l -n --hidden -S '/required-docs|DocumentWarningBanner|bypassedDocuments' client/src 2>/dev/null | tee "$R/step5_files.txt" >/dev/null || true
while IFS= read -r f; do
  [ -f "$f" ] || continue
  node - <<'NODE' "$f" "$CAN_FETCHER"
const fs=require('fs'); const path=require('path'); const [p,fetcher]=process.argv.slice(2); let s=fs.readFileSync(p,'utf8'); const o=s; let changed=false;
const rel = path.relative(path.dirname(p), fetcher).replace(/\\/g,'/').replace(/\.ts$/, ''); const relImp = /^\.\.?\//.test(rel)?rel:'./'+rel;

// replace any raw fetch('/required-docs') calls
s = s.replace(/fetch\([^)]*\/required-docs[^)]*\)[^;]*;?/g,'/* rewired */');

// ensure import present
if(!/from\s+["'][^"']*api\/(products|index)[^"']*["']/.test(s) || !/fetchRequiredDocs/.test(s)){
  if(/import\s*{[^}]*}\s*from\s*["'][^"']*["']/.test(s)){
    // add to first import block
    s = s.replace(/import\s*{([^}]*)}\s*from\s*["'][^"']*["']/,
      (m,g)=> m.includes('fetchRequiredDocs')? m : m.replace(g, (g?g+', ':'')+'fetchRequiredDocs'));
    if(!new RegExp('from\\s+"'+relImp+'"').test(s)) s = `import { fetchRequiredDocs } from "${relImp}";\n` + s;
  } else {
    s = `import { fetchRequiredDocs } from "${relImp}";\n` + s;
  }
  changed=true;
}
// ensure usage prior to render
if(/return\s*\(/.test(s) && !/fetchRequiredDocs\(\)/.test(s)){
  s = s.replace(/return\s*\(/,'const requiredDocs = await fetchRequiredDocs();\nreturn ('); changed=true;
}
// guard legacy banner field
s = s.replace(/(\.bypassedDocuments\b)/g,'?.bypassedDocuments ?? []');
// optionally comment out banner usage if still referenced
s = s.replace(/\bDocumentWarningBanner\b/g,'/* DocumentWarningBanner (disabled) */ DocumentWarningBanner');

if(changed && s!==o){ fs.writeFileSync(p,s); console.log("Rewired Step5 ->",p); }
NODE
done < "$R/step5_files.txt"

# --------------------------------------------------------------------
# 5) Persistence: modify existing provider (no new files) to save/load Step-1 formData
# --------------------------------------------------------------------
PROVIDER=""
for f in client/src/context/ComprehensiveFormProvider.tsx client/src/context/FormDataContext.tsx; do
  [ -f "$f" ] && PROVIDER="$f" && break
done
if [ -n "$PROVIDER" ]; then
  node - <<'NODE' "$PROVIDER"
const fs=require('fs'); const p=process.argv[2]; let s=fs.readFileSync(p,'utf8'); const o=s; let changed=false;
// add imports if missing
if(!/useEffect/.test(s) && /from\s+["']react["']/.test(s)){
  s = s.replace(/from\s+["']react["']\s*;/, 'from "react";\nimport { useEffect } from "react";'); changed=true;
}
// naive detect state/ctx accessors
const hasPersistWrite = /localStorage\.setItem\(\s*["']formData["']/.test(s);
const hasPersistRead  = /localStorage\.getItem\(\s*["']formData["']/.test(s);
if(!hasPersistRead){
  s += `\n// Hydrate Step-1 data on mount\nuseEffect(()=>{try{const saved=localStorage.getItem("formData"); if(saved){ const j=JSON.parse(saved); if(typeof setData==="function"){ setData((prev:any)=>({...prev,...j})); } else if(typeof setState==="function"){ setState((prev:any)=>({...prev,...j})); }} }catch{}},[]);\n`;
  changed=true;
}
if(!hasPersistWrite){
  s += `\n// Persist Step-1 data on change\nuseEffect(()=>{ try{ if(typeof data!=="undefined") localStorage.setItem("formData", JSON.stringify(data||state)); }catch{} }, [data, state]);\n`;
  changed=true;
}
if(changed && s!==o){ fs.writeFileSync(p,s); console.log("Patched provider persistence:",p); }
NODE
else
  echo "Provider not found; skipping persistence patch (not required if app already persists)." | tee -a "$R/20_actions.txt"
fi

# --------------------------------------------------------------------
# 6) Build & Deep Test BEFORE deleting anything
# --------------------------------------------------------------------
BUILD_OK=1
if npm run -s build >>"$R/build.log" 2>&1; then echo "BUILD: OK" | tee -a "$R/summary.txt"; else BUILD_OK=0; echo "BUILD: FAIL — see $R/build.log" | tee -a "$R/summary.txt"; head -120 "$R/build.log" > "$R/build_first_errors.txt" || true; fi

# Write deep test (no duplicates in runtime bundle; lives under tests/)
mkdir -p client/tests
cat > client/tests/step1-compat.spec.ts <<'TS'
import assert from "node:assert/strict";
import { toCanonical } from "../src/api/normalize";
const normStep1 = (d:any)=> {
  const n = (v:any)=> Number((v??'').toString().replace(/[$,_\s]/g,'')) || 0;
  const cc = (v:any)=>{ const s=(v??'').toString().toUpperCase(); if(["CA","CANADA"].includes(s)) return "CA"; if(["US","USA","UNITED STATES"].includes(s)) return "US"; return s.length===2?s:"NA"; };
  return { amount: n(d?.amountRequested ?? d?.loanAmount ?? d?.requestedAmount ?? d?.requested_amount ?? d?.amount ?? d?.fundsNeeded ?? d?.fundingAmount ?? d?.loan_size), country: cc(d?.country ?? d?.countryCode ?? d?.applicantCountry ?? d?.region) };
};
const prods = [
  { id:1, productName:"CA LOC A", category:"Line of Credit", lender_name:"Revenued", country:"CANADA", minAmount:50000,  maxAmount:1000000 },
  { id:2, productName:"US LOC B", category:"Line of Credit", lender_name:"SomeBank", country:"USA",    minAmount:250000, maxAmount:500000 },
  { id:3, productName:"CA Equip", category:"Equipment",      lender_name:"Meridian", country:"CA",     minAmount:200000, maxAmount:null },
  { id:4, productName:"US Fact",  category:"Factoring",      lender_name:"Accord",   country:"US",     minAmount:10000,  maxAmount:200000 },
].map(toCanonical);
const filter = (s1:any)=>{ const s=normStep1(s1); return prods.filter(p => (s.country==="NA"||p.country===s.country) && (s.amount===0 || (p.minAmount<=s.amount && s.amount<=p.maxAmount))); };

it("Step2: CA $500k matches", ()=>{ assert.deepEqual(filter({amountRequested:"$500,000",country:"Canada"}).map(p=>p.id).sort(), [1,3]); });
it("Step2: US $250k matches", ()=>{ assert.deepEqual(filter({loanAmount:250000,country:"US"}).map(p=>p.id).sort(), [2]); });
it("Step5: guards legacy banner", ()=>{ const state:any={}; const x = state?.bypassedDocuments ?? []; assert.ok(Array.isArray(x)); });
TS

# Try vitest/jest/tsx in order
TEST_OK=1
if npx --yes vitest -v >/dev/null 2>&1; then
  (cd client && npx --yes vitest run --reporter=basic) | tee "$R/test.log" || TEST_OK=0
elif npx --yes jest -v >/dev/null 2>&1; then
  (cd client && npx --yes jest --runInBand) | tee "$R/test.log" || TEST_OK=0
else
  # run with tsx directly (create a runner wrapper)
  npx --yes tsx -e 'import("./client/tests/step1-compat.spec.ts").then(()=>console.log("Tests loaded")).catch(e=>{console.error(e);process.exit(1)})' 2>&1 | tee "$R/test.log" || TEST_OK=0
fi

# Abort permanent deletion on failures
if [ "$BUILD_OK" -ne 1 ] || [ "$TEST_OK" -ne 1 ]; then
  echo "⛔ Build or tests failed. No deletions performed. See $R/ for details." | tee -a "$R/summary.txt"
  exit 1
fi

# --------------------------------------------------------------------
# 7) After success: REMOVE legacy duplicates (or quarantine if NUKE!=1)
# --------------------------------------------------------------------
# Candidates: previous ad-hoc modules & rewiring leftovers
CANDIDATES=()
CANDIDATES+=("client/src/api/products-recommended.ts")
CANDIDATES+=("client/src/lib/products.ts")
CANDIDATES+=("client/src/lib/api.ts.bak" "client/src/api/products.old.ts" "client/src/api/products.backup.ts")
CANDIDATES+=("client/src/v2-design-system/DocumentWarningBanner.tsx") # if fully disabled elsewhere & still exists

REMOVED=0
for f in "${CANDIDATES[@]}"; do
  [ -f "$f" ] || continue
  if [ "${NUKE:-0}" = "1" ]; then
    rm -f "$f" && echo "DELETED: $f" | tee -a "$R/40_removed.txt"
  else
    mkdir -p "$TRASH/$(dirname "$f")"; mv "$f" "$TRASH/$f" && echo "QUARANTINED: $f -> $TRASH/$f" | tee -a "$R/40_removed.txt"
  fi
  REMOVED=$((REMOVED+1))
done

# Remove parallel extension duplicates where a .ts/.tsx exists
find client -type f \( -name '*.js' -o -name '*.mjs' \) | while read -r f; do
  base="${f%.*}"
  if [ -f "${base}.ts" ] || [ -f "${base}.tsx" ]; then
    if [ "${NUKE:-0}" = "1" ]; then rm -f "$f" && echo "DELETED parallel: $f" | tee -a "$R/40_removed.txt"; else mkdir -p "$TRASH/$(dirname "$f")"; mv "$f" "$TRASH/$f" && echo "QUARANTINED parallel: $f" | tee -a "$R/40_removed.txt"; fi
    REMOVED=$((REMOVED+1))
  fi
done

# --------------------------------------------------------------------
# 8) Final summary + Verify tips
# --------------------------------------------------------------------
{
  echo ""
  echo "=== CLIENT ZERO-DUPE SUMMARY ==="
  echo "Reports: $R"
  echo "Trash:   $TRASH"
  echo "Build:   OK"
  echo "Tests:   OK"
  echo "Removed/Quarantined: $REMOVED file(s) (set NUKE=1 to permanently delete)"
  echo ""
  echo "Step 2 now reads products via getRecommendedProducts() (amount+country derived from Step-1 aliases)."
  echo "Step 5 now uses fetchRequiredDocs() and guards legacy banner fields."
  echo ""
  echo "If UI still shows stale behavior, clear Service Worker cache: DevTools → Application → Clear storage & Unregister SW, then hard reload."
} | tee -a "$R/summary.txt"

exit 0
```
