# CLIENT APP — STEP 5 DOCUMENTS E2E (Collect → Hand-off → Process → Banking Analysis → Store → Lender Export)
# Goal: Prove ALL Step 5 docs flow end-to-end, and that **every** Step 1–4 field is preserved in the submission trace.
# - Idempotent. Zero-duplicate policy: only patch in place; quarantine legacy telemetry if replaced.
# - Uses JSON upload with base64 to avoid multipart dependency issues; adds X-Trace-Id and unions manifest+runtime fields.
# Reports: reports/client-docs-e2e-<ts>/

set -euo pipefail

TS="$(date +%F_%H-%M-%S)"
R="reports/client-docs-e2e-$TS"
TRASH=".trash-client-$TS"
mkdir -p "$R" "$TRASH"

command -v rg >/dev/null || alias rg='grep -R'
command -v jq >/dev/null || { echo "jq is required"; exit 1; }

BASE="${VITE_STAFF_API_URL:-https://staff.boreal.financial/api}"
TOK="${VITE_CLIENT_APP_SHARED_TOKEN:-}"

log(){ echo "$@" | tee -a "$R/log.txt"; }
pass(){ echo "STEP $1: PASS" | tee -a "$R/summary.txt"; }
fail(){ echo "STEP $1: FAIL" | tee -a "$R/summary.txt"; }

# --------------------------------------------------------------------------------
# 0) Ensure canonical FIELD MANIFEST + lineage (no duplicates) for full payload tracing
# --------------------------------------------------------------------------------
SCAN_ROOT="client/src"
MAN_MOD_TS="client/src/telemetry/field-manifest.ts"
LINEAGE_MOD="client/src/telemetry/lineage.ts"
mkdir -p "$(dirname "$MAN_MOD_TS")"

# Build/update manifest from Steps 1–4 + Step 5
node - <<'NODE' "$SCAN_ROOT" "$R/manifest.raw.json" "$MAN_MOD_TS"
const fs=require('fs'), path=require('path');
const [root,outRaw,outTs]=process.argv.slice(2);
const glob=(d)=>{const out=[];const walk=(x)=>{for(const e of fs.readdirSync(x,{withFileTypes:true})){const p=path.join(x,e.name);
 if(e.isDirectory()){ if(e.name==='node_modules'||e.name.startsWith('.trash')) continue; walk(p);} else if(/\.(tsx?|jsx?)$/.test(e.name)) out.push(p);} }; walk(d); return out;};
const stepOf=(f)=>{const s=f.toLowerCase(); if(/step1/.test(s))return'step1'; if(/step2|recommend/.test(s))return'step2';
 if(/step3/.test(s))return'step3'; if(/step4/.test(s))return'step4'; if(/step5|doc|required-doc/.test(s))return'step5'; return'other';};
const rx={ register:/\bregister\s*\(\s*['"]([^'"]+)['"]/g, getValues:/\bgetValues\s*\(\s*['"]([^'"]+)['"]/g,
 formDot:/\b(formData|data|values|answers)\.([A-Za-z0-9_]+)\b/g, nameAttr:/\bname\s*=\s*['"]([^'"]+)['"]/g,
 zod:/\bz\.object\s*\(\s*\{([\s\S]*?)\}\s*\)/g };
const files=glob(root).filter(p=>/client[\/\\]src/.test(p));
const sets={step1:new Set(),step2:new Set(),step3:new Set(),step4:new Set(),step5:new Set(),other:new Set()};
for(const f of files){ const key=sets[stepOf(f)]? stepOf(f):'other'; let s=''; try{s=fs.readFileSync(f,'utf8');}catch{}
 for(const [name,re] of Object.entries(rx)){ let m; re.lastIndex=0; while((m=re.exec(s))){
  if(name==='formDot'){ sets[key].add(m[2]); continue; }
  if(name==='zod'){ const blk=m[1]; const keys=[...blk.matchAll(/\b([A-Za-z0-9_]+)\s*:/g)].map(x=>x[1]); keys.forEach(k=>sets[key].add(k)); continue; }
  sets[key].add(m[1]); } } }
const norm=o=>Object.fromEntries(Object.entries(o).map(([k,v])=>[k,[...v].sort()]));
const all=[...new Set([].concat(...Object.values(sets).map(s=>[...s])))].sort();
const out={byStep:norm(sets), all};
try{fs.writeFileSync(outRaw,JSON.stringify(out,null,2));}catch{}
const header=`// AUTO-GENERATED — CANONICAL FIELD MANIFEST (Steps 1–5)
export const FIELD_MANIFEST = ${JSON.stringify(out,null,2)} as const;
export type FieldName = typeof FIELD_MANIFEST.all[number];
export default FIELD_MANIFEST;`;
fs.writeFileSync(outTs,header);
console.log("Generated manifest:",outTs,"total fields:",all.length);
NODE

jq '.all|length as $n | "fields=\($n)"' "$R/manifest.raw.json" | tee -a "$R/log.txt" || true

# Ensure lineage helper exists/updated
if [ ! -f "$LINEAGE_MOD" ]; then
  cat > "$LINEAGE_MOD" <<'TS'
import { FIELD_MANIFEST } from "./field-manifest";
let __tid: string | null = null;
export function getTraceId():string{ if(__tid) return __tid; try{ __tid=crypto?.randomUUID?.()||Math.random().toString(36).slice(2);}catch{__tid=Math.random().toString(36).slice(2);} try{localStorage.setItem("__traceId",__tid);}catch{} return __tid; }
export function flatten(obj:any,prefix:string[]=[]):Record<string,any>{ const out:Record<string,any>={}; const isObj=(v:any)=>v&&typeof v==='object'&&!Array.isArray(v);
 const walk=(o:any,pre:string[])=>{ if(Array.isArray(o)){o.forEach((v,i)=>walk(v,[...pre,String(i)]));return;} if(isObj(o)){Object.entries(o).forEach(([k,v])=>walk(v,[...pre,k]));return;} out[pre.join('.')]=o;};
 walk(obj??{},prefix); return out; }
export function attachTrace(payload:any,runtime:any){ const id=getTraceId(); let rf:string[]=[]; try{rf=Object.keys(flatten(runtime||{}));}catch{} const union=Array.from(new Set([...(FIELD_MANIFEST?.all||[]),...rf])).sort(); return { ...(payload||{}), _trace:{ id, version:"1.3", fields:union } }; }
export default { getTraceId, attachTrace, flatten };
TS
else
  node - <<'NODE' "$LINEAGE_MOD"
const fs=require('fs'),p=process.argv[2]; let s=fs.readFileSync(p,'utf8'),o=s;
if(!/FIELD_MANIFEST/.test(s)) s=`import { FIELD_MANIFEST } from "./field-manifest";\n`+s;
if(!/attachTrace\(/.test(s)) s+=`\nexport function attachTrace(payload:any,runtime:any){ return { ...(payload||{}), _trace:{ id:'no-trace', version:'1.3', fields:(FIELD_MANIFEST?.all||[]) } }; }\n`;
if(s!==o){ fs.writeFileSync(p,s); console.log("Patched lineage:",p); }
NODE
fi
pass "0/7 manifest+lineage ready"

# --------------------------------------------------------------------------------
# 1) Ensure submit/uploader attach trace + headers (no duplicates)
# --------------------------------------------------------------------------------
UPL_FILE="$(rg -n --glob 'client/src/**/*.{ts,tsx}' -S 'upload' -l | head -1 || true)"
SUBMIT_FILE="$(rg -n --glob 'client/src/**/*.{ts,tsx}' -S 'submitApplication|createApplication' -l | head -1 || true)"
[ -n "$SUBMIT_FILE" ] || { fail "1/7 submit not found"; exit 1; }

# Patch submit: JSON.stringify(attachTrace(...)), add X-Trace-Id
node - <<'NODE' "$SUBMIT_FILE"
const fs=require('fs'),p=process.argv[2]; let s=fs.readFileSync(p,'utf8'),o=s,changed=false;
if(!/telemetry\/lineage/.test(s)){ s=`import { attachTrace, getTraceId } from "../telemetry/lineage";\n`+s; changed=true; }
if(!/JSON\.stringify\(\s*attachTrace\(/.test(s)){ s=s.replace(/JSON\.stringify\(\s*([^)]+)\s*\)/g,'JSON.stringify(attachTrace($1,(typeof formData!=="undefined"?formData:(typeof data!=="undefined"?data:{}))))'); changed=true; }
if(!/X-Trace-Id/.test(s)){ s=s.replace(/headers\s*:\s*\{([^}]*)\}/,(m,ins)=>`headers:{${ins}, 'X-Trace-Id': getTraceId(), 'X-Client-App':'boreal-client'}`); changed=true; }
if(changed && s!==o){ fs.writeFileSync(p,s); console.log("Patched submit:",p); }
NODE

# If there is a specific uploads API file, ensure it can send JSON base64 as fallback
if [ -n "${UPL_FILE:-}" ] && [ -f "$UPL_FILE" ]; then
  node - <<'NODE' "$UPL_FILE"
const fs=require('fs'),p=process.argv[2]; let s=fs.readFileSync(p,'utf8'),o=s,changed=false;
if(/fetch\(/.test(s) && !/X-Trace-Id/.test(s)){ s=s.replace(/headers\s*:\s*\{([^}]*)\}/,(m,ins)=>`headers:{${ins}, 'X-Trace-Id': (typeof getTraceId==='function'?getTraceId(): 'no-trace') }`); changed=true; }
if(!/content_base64/.test(s) && /FormData\(/.test(s)){ s+=`\n// NOTE: Test-mode JSON upload supported by staff /api/test/docs/upload (base64)\n`; changed=true; }
if(changed && s!==o){ fs.writeFileSync(p,s); console.log("Patched uploader:",p); }
NODE
fi
pass "1/7 submit/uploader headers+trace"

# --------------------------------------------------------------------------------
# 2) Synthesize sample Step 5 docs and encode base64
# --------------------------------------------------------------------------------
SAMPLE_DIR="$R/samples"; mkdir -p "$SAMPLE_DIR"
cat > "$SAMPLE_DIR/bank.csv" <<'CSV'
date,description,amount,balance
2025-05-01,Opening Balance,0,12000
2025-05-03,Client Payment,8500,20500
2025-05-10,Office Rent,-3200,17300
2025-05-18,NSF Fee,-45,17255
2025-05-24,Card Sales,4200,21455
CSV
echo "Driver License: John Appleseed, AB, 2029-12-31" > "$SAMPLE_DIR/id.txt"
echo "May/June Bank Statements placeholder text" > "$SAMPLE_DIR/statements.txt"

b64(){ base64 | tr -d '\n'; }

BANK_B64="$(b64 < "$SAMPLE_DIR/bank.csv")"
ID_B64="$(b64 < "$SAMPLE_DIR/id.txt")"
STMTS_B64="$(b64 < "$SAMPLE_DIR/statements.txt")"

echo "$BANK_B64" > "$R/bank.b64"
echo "$ID_B64" > "$R/id.b64"
echo "$STMTS_B64" > "$R/statements.b64"
pass "2/7 sample docs created"

# --------------------------------------------------------------------------------
# 3) Create synthetic full payload (answers) to accompany doc submission
# --------------------------------------------------------------------------------
node - <<'NODE' "$R/manifest.raw.json" "$R/answers.json"
const fs=require('fs'); const [mPath,out]=process.argv.slice(2); const m=JSON.parse(fs.readFileSync(mPath,'utf8'));
const now=new Date().toISOString().slice(0,10);
const sample=(k)=>/amount|loan|revenue|sales|payroll|debt/.test(k)?500000:/country/.test(k)?"CA":/province|state/.test(k)?"AB":/date/.test(k)?now:/email/.test(k)?"borrower@example.com":/phone/.test(k)?"+1-555-010-1212":/name/.test(k)?"Acme Corp":"sample";
const answers=Object.fromEntries(m.all.map(k=>[k,sample(k.toLowerCase())]));
const payload={ applicationDate: now, applicant:{ legalName: answers.legalName||"Acme Corp" }, answers };
fs.writeFileSync(out, JSON.stringify(payload,null,2));
NODE
jq '.answers|keys|length as $n | "answers_fields=\($n)"' "$R/answers.json" | tee -a "$R/log.txt" || true
pass "3/7 synthetic answers built"

# --------------------------------------------------------------------------------
# 4) Send docs (JSON base64) to Staff test docs API
# --------------------------------------------------------------------------------
TRACE_ID="$(node -e 'console.log(crypto?.randomUUID?.()||Math.random().toString(36).slice(2))' 2>/dev/null || echo trace-$TS)"
AUTH_HDR=(); [ -n "$TOK" ] && AUTH_HDR=(-H "Authorization: Bearer $TOK")

upload_doc () {
  local filename="$1" mimetype="$2" category="$3" content_b64_file="$4"
  curl -s -X POST "${AUTH_HDR[@]}" \
    -H "Content-Type: application/json" \
    -H "X-Trace-Id: $TRACE_ID" \
    -d @<(jq -n --arg fn "$filename" --arg mt "$mimetype" --arg cat "$category" --rawfile b64 "$content_b64_file" \
      '{filename:$fn, mimetype:$mt, category:$cat, content_base64: ($b64)}') \
    "${BASE%/api}/api/test/docs/upload" | tee "$R/upload-$filename.json" >/dev/null || true
}

upload_doc "bank.csv" "text/csv" "bank_statement" "$R/bank.b64"
upload_doc "id.txt" "text/plain" "identity_document" "$R/id.b64"
upload_doc "statements.txt" "text/plain" "bank_statement" "$R/statements.b64"

DOC_IDS="$(jq -r '.docId? // empty' "$R"/upload-*.json | tr '\n' ',' | sed 's/,$//')"
echo "doc_ids=[${DOC_IDS}]" | tee -a "$R/log.txt"
pass "4/7 docs uploaded"

# --------------------------------------------------------------------------------
# 5) Submit answers + docIds for card/pdf/lender export simulation
# --------------------------------------------------------------------------------
curl -s -X POST "${AUTH_HDR[@]}" \
  -H "Content-Type: application/json" -H "X-Trace-Id: $TRACE_ID" \
  -d @<(jq -n --rawfile ans "$R/answers.json" --argjson ids "[${DOC_IDS:-}]" \
      '$ans|fromjson as $A | {answers:$A.answers, applicationDate:$A.applicationDate, docIds: $ids}') \
  "${BASE%/api}/api/test/docs/submit" | tee "$R/submit.json" >/dev/null || true

jq '.coverage // {}' "$R/submit.json" | tee "$R/coverage.json" >/dev/null || true
pass "5/7 submit+coverage"

# --------------------------------------------------------------------------------
# 6) Build client to ensure telemetry compiles with manifest changes
# --------------------------------------------------------------------------------
BUILD_OK=1
npm run -s build >>"$R/build.log" 2>&1 || BUILD_OK=0
[ "$BUILD_OK" -eq 1 ] && pass "6/7 build" || fail "6/7 build (see $R/build.log)"

# --------------------------------------------------------------------------------
# 7) Quarantine legacy telemetry duplicates (only if both upload & submit okay)
# --------------------------------------------------------------------------------
if jq -e '.ok==true' "$R/submit.json" >/dev/null 2>&1; then
  for f in client/src/telemetry/trace.ts client/src/telemetry/field-manifest.json client/src/telemetry/lineage.old.ts; do
    [ -f "$f" ] || continue
    mkdir -p "$TRASH/$(dirname "$f")"; mv "$f" "$TRASH/$f"
    echo "QUARANTINED legacy telemetry: $f" | tee -a "$R/removed.txt"
  done
  pass "7/7 dedupe"
else
  log "Skipped dedupe because submit did not return ok:true"
fi

echo ""
echo "=== FINAL SUMMARY — CLIENT STEP 5 DOCS E2E ===" | tee -a "$R/summary.txt"
echo "Trace: $TRACE_ID" | tee -a "$R/summary.txt"
echo "Uploads: $R/upload-*.json  Submit: $R/submit.json  Coverage: $R/coverage.json" | tee -a "$R/summary.txt"
echo "Verify last on Staff: curl -s '${BASE%/api}/api/test/docs/last' | jq" | tee -a "$R/summary.txt"
