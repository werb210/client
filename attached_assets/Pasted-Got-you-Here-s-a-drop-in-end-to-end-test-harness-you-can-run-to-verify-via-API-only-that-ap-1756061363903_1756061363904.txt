Got you. Here’s a drop-in **end-to-end test harness** you can run to verify—via API only—that:

* applications are accepted by the Staff app
* documents upload and land in S3
* fields map into the application card
* documents appear under the application’s Documents tab
* OCR + banking analysis jobs run and return results

Everything below is self-contained. Paste the files and run.

---

# 1) Env you’ll need

Set these before running:

```bash
export STAFF_API_URL="https://staff.boreal.financial"   # or http://localhost:5000
export TENANT="bf"                                      # bf or slf
export AUTH_TOKEN=""                                    # if Staff requires bearer auth, otherwise leave empty
# (optional if you want S3 verification via AWS CLI)
export AWS_REGION="ca-central-1"
export S3_BUCKET="your-bucket-name"
```

---

# 2) Create the test script

Create `scripts/e2e/e2e_app_submission.sh`:

```bash
#!/usr/bin/env bash
set -euo pipefail

# ---------- Config ----------
API="${STAFF_API_URL:-http://localhost:5000}"
TENANT="${TENANT:-bf}"
AUTH="${AUTH_TOKEN:-}"

hdr_auth=()
if [[ -n "${AUTH}" ]]; then
  hdr_auth=(-H "Authorization: Bearer ${AUTH}")
fi

# ---------- Helpers ----------
jqget () { jq -r "$1"; }

say () { printf "\n\033[1m%s\033[0m\n" "$*"; }

require() {
  command -v "$1" >/dev/null 2>&1 || { echo "Missing $1. Please install."; exit 1; }
}

# Create tiny valid-ish PDFs for upload (accepted by most validators)
mkpdf () {
  f="$1"
  cat > "$f" <<'PDF'
%PDF-1.4
1 0 obj
<< /Type /Catalog /Pages 2 0 R>>
endobj
2 0 obj
<< /Type /Pages /Kids [3 0 R] /Count 1>>
endobj
3 0 obj
<< /Type /Page /Parent 2 0 R /MediaBox [0 0 200 200] /Contents 4 0 R >>
endobj
4 0 obj
<< /Length 44 >>
stream
BT /F1 12 Tf 50 150 Td (Test PDF) Tj ET
endstream
endobj
xref
0 5
0000000000 65535 f 
0000000010 00000 n 
0000000061 00000 n 
0000000121 00000 n 
0000000225 00000 n 
trailer
<< /Root 1 0 R /Size 5>>
startxref
318
%%EOF
PDF
}

# POST JSON with curl + jq
post_json () {
  local url="$1"; shift
  curl -fsS -X POST "$url" \
    -H "Content-Type: application/json" \
    "${hdr_auth[@]}" \
    -d "$*" 
}

# Try multiple application endpoints (some repos use different paths)
create_application () {
  local payload="$1"
  for ep in \
    "/api/public/applications" \
    "/public/applications" \
    "/api/applications/create" \
    "/api/applications"
  ; do
    say "Submitting application to ${ep} …"
    if out="$(post_json "${API}${ep}" "${payload}" 2>/dev/null || true)"; then
      if [[ -n "$out" ]] && appId="$(echo "$out" | jq -r '.applicationId // .id // empty')"; then
        if [[ -n "$appId" ]]; then
          echo "$out" | jq . >/dev/null
          echo "$appId"
          return 0
        fi
      fi
    fi
  done
  echo ""
  return 1
}

upload_doc_multipart () {
  local appId="$1"; local dtype="$2"; local file="$3"
  # Common patterns seen in codebases:
  for ep in \
    "/api/documents/upload" \
    "/api/applications/${appId}/documents" \
    "/api/documents"
  ; do
    say "Uploading ${dtype} via ${ep} …"
    if curl -fsS -X POST "${API}${ep}" \
      "${hdr_auth[@]}" \
      -F "applicationId=${appId}" \
      -F "documentType=${dtype}" \
      -F "file=@${file};type=application/pdf" >/dev/null 2>&1
    then
      echo "OK"; return 0
    fi
  done
  return 1
}

presign_and_put () {
  local appId="$1"; local dtype="$2"; local file="$3"
  for ep in \
    "/api/documents/presign" \
    "/api/applications/${appId}/documents/presign"
  ; do
    say "Requesting presign: ${ep} …"
    if pres="$(post_json "${API}${ep}" "$(jq -n --arg a "$appId" --arg t "$dtype" '{applicationId:$a, documentType:$t, contentType:"application/pdf"}')" 2>/dev/null || true)"; then
      putUrl="$(echo "$pres" | jq -r '.url // .putUrl // empty')"
      key="$(echo "$pres" | jq -r '.key // .objectKey // empty')"
      if [[ -n "$putUrl" && -n "$key" ]]; then
        say "PUT to S3 signed URL …"
        curl -fsS -X PUT "$putUrl" --data-binary @"$file" -H "Content-Type: application/pdf" >/dev/null
        echo "$key"
        return 0
      fi
    fi
  done
  echo ""
  return 1
}

aws_verify () {
  local key="$1"
  if [[ -n "${S3_BUCKET:-}" ]]; then
    if aws s3 ls "s3://${S3_BUCKET}/${key}" >/dev/null 2>&1; then
      echo "s3://${S3_BUCKET}/${key}"
      return 0
    fi
  fi
  return 1
}

fetch_application_card () {
  local appId="$1"
  # Known patterns
  for ep in \
    "/api/pipeline/cards/${appId}/application" \
    "/api/applications/${appId}" \
    "/api/pipeline/application/${appId}"
  ; do
    if out="$(curl -fsS "${API}${ep}" "${hdr_auth[@]}" 2>/dev/null || true)"; then
      if [[ -n "$out" ]]; then echo "$out"; return 0; fi
    fi
  done
  echo ""
  return 1
}

list_documents () {
  local appId="$1"
  for ep in \
    "/api/applications/${appId}/documents" \
    "/api/documents?applicationId=${appId}" \
    "/api/pipeline/cards/${appId}/documents"
  ; do
    if out="$(curl -fsS "${API}${ep}" "${hdr_auth[@]}" 2>/dev/null || true)"; then
      if [[ -n "$out" ]]; then echo "$out"; return 0; fi
    fi
  done
  echo ""
  return 1
}

start_ocr () {
  local appId="$1"
  for ep in \
    "/api/ocr/start" \
    "/api/applications/${appId}/ocr/start" \
    "/api/documents/ocr/start"
  ; do
    if out="$(post_json "${API}${ep}" "$(jq -n --arg a "$appId" '{applicationId:$a}')" 2>/dev/null || true)"; then
      job="$(echo "$out" | jq -r '.jobId // .id // empty')"
      if [[ -n "$job" ]]; then echo "$job"; return 0; fi
    fi
  done
  echo ""
  return 1
}

start_banking () {
  local appId="$1"
  for ep in \
    "/api/banking/analyze" \
    "/api/applications/${appId}/banking/analyze"
  ; do
    if out="$(post_json "${API}${ep}" "$(jq -n --arg a "$appId" '{applicationId:$a}')" 2>/dev/null || true)"; then
      job="$(echo "$out" | jq -r '.jobId // .id // empty')"
      if [[ -n "$job" ]]; then echo "$job"; return 0; fi
    fi
  done
  echo ""
  return 1
}

poll_status () {
  local what="$1"; local id="$2"
  for ep in \
    "/api/${what}/status/${id}" \
    "/api/jobs/${id}" \
    "/api/${what}/${id}/status"
  ; do
    for _ in {1..20}; do
      out="$(curl -fsS "${API}${ep}" "${hdr_auth[@]}" 2>/dev/null || true)"
      if [[ -n "$out" ]]; then
        st="$(echo "$out" | jq -r '.status // .state // empty')"
        echo "status: $st"
        case "$st" in
          succeeded|success|complete|completed) return 0 ;;
          failed|error) echo "$out" | jq .; return 2 ;;
        esac
        sleep 1
      fi
    done
  done
  return 1
}

# ---------- Begin ----------
require curl
require jq

workdir="$(mktemp -d)"
trap 'rm -rf "$workdir"' EXIT

say "Generating sample PDFs …"
mkpdf "${workdir}/financials.pdf"
mkpdf "${workdir}/bankstatements.pdf"
mkpdf "${workdir}/taxreturns.pdf"

say "Building application payload …"
payload="$(jq -n \
  --arg tenant "$TENANT" \
  --arg name "Acme Fabrication Ltd" \
  --arg email "owner@acmefab.test" \
  --arg phone "+1-555-555-1234" \
  --arg amount "250000" \
  --arg use "Working Capital" \
  '{
    tenant:$tenant,
    applicantInformation:{ firstName:"Jane", lastName:"Founder", email:$email, phone:$phone },
    businessInformation:{ businessName:$name, businessType:"Construction", yearsInBusiness:5, annualRevenue:9307052, country:"CA" },
    requestedAmount: ($amount|tonumber),
    loanPurpose:$use
  }'
)"

say "Submitting application to Staff …"
appId="$(create_application "$payload" || true)"
if [[ -z "$appId" ]]; then
  echo "❌ Could not submit application (all endpoints failed)."
  exit 1
fi
echo "Application ID: $appId"

say "Uploading documents (multipart attempt) …"
okcount=0
upload_doc_multipart "$appId" "Financial Statements" "${workdir}/financials.pdf" && ((okcount++)) || true
upload_doc_multipart "$appId" "Bank Statements"     "${workdir}/bankstatements.pdf" && ((okcount++)) || true
upload_doc_multipart "$appId" "Tax Returns"         "${workdir}/taxreturns.pdf" && ((okcount++)) || true

if (( okcount < 3 )); then
  say "Multipart failed for one or more docs; trying presigned flow …"
  key1="$(presign_and_put "$appId" "Financial Statements" "${workdir}/financials.pdf" || true)"
  key2="$(presign_and_put "$appId" "Bank Statements"      "${workdir}/bankstatements.pdf" || true)"
  key3="$(presign_and_put "$appId" "Tax Returns"          "${workdir}/taxreturns.pdf" || true)"
  if [[ -n "${S3_BUCKET:-}" ]]; then
    say "Verifying S3 objects via AWS CLI …"
    [[ -n "$key1" ]] && aws_verify "$key1" || true
    [[ -n "$key2" ]] && aws_verify "$key2" || true
    [[ -n "$key3" ]] && aws_verify "$key3" || true
  fi
fi

say "Fetching application card …"
card="$(fetch_application_card "$appId" || true)"
if [[ -z "$card" ]]; then
  echo "❌ Could not fetch application card details."
  exit 1
fi
echo "$card" | jq '{application: .application // ., documentCount: .documentCount // .documents|length // 0}' 

# Basic field assertions (non-empty)
app_name="$(echo "$card" | jq -r '.application.businessName // .businessName // empty')"
first="$(echo "$card" | jq -r '.application.applicant.firstName // .applicant.firstName // empty')"
last="$(echo "$card" | jq -r '.application.applicant.lastName // .applicant.lastName // empty')"
if [[ -z "$app_name" || -z "$first" || -z "$last" ]]; then
  echo "❌ Field mapping looks wrong (missing business or applicant names)."
  exit 1
fi

say "Listing documents for the application …"
docs="$(list_documents "$appId" || true)"
if [[ -z "$docs" ]]; then
  echo "❌ Could not list documents."
  exit 1
fi
echo "$docs" | jq '.[0:10]'

doc_count="$(echo "$docs" | jq 'length')"
if (( doc_count < 3 )); then
  echo "❌ Expected ≥3 documents, found ${doc_count}."
  exit 1
fi

say "Starting OCR job …"
ocr_job="$(start_ocr "$appId" || true)"
if [[ -z "$ocr_job" ]]; then
  echo "⚠️  OCR start endpoint not found; skipping OCR run."
else
  poll_status "ocr" "$ocr_job" || { echo "❌ OCR reported failure."; exit 1; }
fi

say "Starting Banking Analysis …"
bank_job="$(start_banking "$appId" || true)"
if [[ -z "$bank_job" ]]; then
  echo "⚠️  Banking analysis endpoint not found; skipping banking run."
else
  poll_status "banking" "$bank_job" || { echo "❌ Banking analysis reported failure."; exit 1; }
fi

say "✅ E2E PASS"
echo "Application ${appId} accepted; documents uploaded; fields mapped; docs present; OCR/Banking (if available) succeeded."
```

Make it executable:

```bash
chmod +x scripts/e2e/e2e_app_submission.sh
```

---

# 3) Run it

```bash
./scripts/e2e/e2e_app_submission.sh
```

**A passing run prints:**

* the new `Application ID`
* a JSON summary with business/applicant names and `documentCount`
* a list of the first few documents
* `status: succeeded` (or similar) for OCR and banking jobs
* final line: `✅ E2E PASS`

---

# 4) What the script validates

1. **Application acceptance**
   Tries common Staff endpoints, captures the new `applicationId`.

2. **Document pipeline**
   Attempts **multipart** upload first; if your stack uses presigned S3, it switches and PUTs to the signed URL.
   (Optional) If you provided `S3_BUCKET`, it **verifies the object in S3** via `aws s3 ls`.

3. **Field mapping into the card**
   Fetches the card via known endpoints and asserts **businessName + applicant first/last name** are present.

4. **Documents visible to UI**
   Calls document listing endpoints; **expects ≥ 3 docs** attached to the application (what the UI uses for the Documents tab).

5. **OCR + Banking**
   Starts jobs (if your API exposes them) and **polls** until they **succeed** (or surfaces errors if they fail/missing).

---

# 5) If something fails, the message tells you where

* **“all endpoints failed”** → Staff app path is different or blocked by auth.
  Fix: expose one of the tested endpoints or update the script path to your canonical one.

* **“Field mapping looks wrong”** → server still defaulting to fallback (“Unknown Business”) or not converting client schema.
  Fix: keep the server’s format converter on and ensure `/api/pipeline/cards/:id/application` resolves mapped fields.

* **“Expected ≥3 documents”** → upload endpoints accepted the request but didn’t persist.
  Fix: confirm your document controller persists the record after S3 upload and associates `applicationId`.

* **OCR/Banking skipped** → endpoints not present.
  Fix: wire start + status endpoints; the script will automatically validate once available.

---

This gives you a single-command, repeatable **proof** that the whole submission path works end-to-end—including S3, mapping, and analysis. Run it after each change (or wire it into CI) and you’ll immediately know if anything regresses.
